{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次的作業是這樣的，希望你能利用本週教的keras functional API，\n",
    "\n",
    "設計一個mnist的分類模型，這個模型可以一次訓練十個獨立的全連接層，\n",
    "\n",
    "每一個獨立的全連接層的目標是學習答案的十維向量裡的其中一個element，\n",
    "\n",
    "每個全連接層有十個神經元，且都跟隨一個average layer把它的輸出做平均，\n",
    "\n",
    "最後再把這十個層的輸出連接起來，取softmax之後比較結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#keras \n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten, Permute, Conv1D, Conv2D, Add, Conv2DTranspose \n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, concatenate, Lambda, Conv2D, Reshape, BatchNormalization, Lambda, Activation \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import softmax\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 把mnist load 進來\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# 把每個像素的值從(0~255)->(0, 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一下Average\n",
    "# 喔，keepdims這個參數在這裏真是他X的重要\n",
    "def average_function(inputs):\n",
    "    return K.mean(inputs, axis=-1, keepdims=True)\n",
    "\n",
    "#把定義好的Average用Lambda封裝起來變成layer\n",
    "average_layer = Lambda(average_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model_input = Input(shape=(28, 28))\n",
    "flatten = Flatten()(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請給我十個分開的Dense層，每個層裡面有十個神經元，且輸入都來自flatten\n",
    "# activation function請用relu\n",
    "f_1 = Dense(10, activation = 'relu')\n",
    "x_1 = f_1(flatten)\n",
    "\n",
    "f_2 = Dense(10, activation = 'relu')\n",
    "x_2 = f_2(flatten)\n",
    "\n",
    "f_3 = Dense(10, activation = 'relu')\n",
    "x_3 = f_3(flatten)\n",
    "\n",
    "f_4 = Dense(10, activation = 'relu')\n",
    "x_4 = f_4(flatten)\n",
    "\n",
    "f_5 = Dense(10, activation = 'relu')\n",
    "x_5 = f_5(flatten)\n",
    "\n",
    "f_6 = Dense(10, activation = 'relu')\n",
    "x_6 = f_6(flatten)\n",
    "\n",
    "f_7 = Dense(10, activation = 'relu')\n",
    "x_7 = f_7(flatten)\n",
    "\n",
    "f_8 = Dense(10, activation = 'relu')\n",
    "x_8 = f_8(flatten)\n",
    "\n",
    "f_9 = Dense(10, activation = 'relu')\n",
    "x_9 = f_9(flatten)\n",
    "\n",
    "f_10 = Dense(10, activation = 'relu')\n",
    "x_10 = f_10(flatten)\n",
    "\n",
    "# 每一個Dense層後面都必須再接一個 average_layer，然後把這十個層整理成一個list\n",
    "# 舉例： \n",
    "# x_1 = Dense(10)\n",
    "# avg_1 = averge_layer(x_1)\n",
    "# list.append(...)\n",
    "# 這不是完整的答案，只是個提示。\n",
    "# 且答案不侷限於上述寫法，有更簡潔明快的做法\n",
    "average_list = []\n",
    "\n",
    "avg_1 = average_layer(x_1)\n",
    "average_list.append(avg_1)\n",
    "\n",
    "avg_2 = average_layer(x_2)\n",
    "average_list.append(avg_2)\n",
    "\n",
    "avg_3 = average_layer(x_3)\n",
    "average_list.append(avg_3)\n",
    "\n",
    "avg_4 = average_layer(x_4)\n",
    "average_list.append(avg_4)\n",
    "\n",
    "avg_5 = average_layer(x_5)\n",
    "average_list.append(avg_5)\n",
    "\n",
    "avg_6 = average_layer(x_6)\n",
    "average_list.append(avg_6)\n",
    "\n",
    "avg_7 = average_layer(x_7)\n",
    "average_list.append(avg_7)\n",
    "\n",
    "avg_8 = average_layer(x_8)\n",
    "average_list.append(avg_8)\n",
    "\n",
    "avg_9 = average_layer(x_9)\n",
    "average_list.append(avg_9)\n",
    "\n",
    "avg_10 = average_layer(x_10)\n",
    "average_list.append(avg_10)\n",
    "\n",
    "# 請把這十個層用學長教過的concatenate層連接起來（基本上就是把上面的average_list放進去並加上其他參數。）\n",
    "concatenate_layer = concatenate(average_list)\n",
    "\n",
    "# Hint: 這次的作業就只有上面的 pass 跟 None 的部分，\n",
    "# 當然你也可以大方地使用 python 的 list comprehension 功能，\n",
    "# 這樣可以少寫幾行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           dense_42[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "                                                                 dense_44[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "                                                                 dense_46[0][0]                   \n",
      "                                                                 dense_47[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "                                                                 dense_49[0][0]                   \n",
      "                                                                 dense_50[0][0]                   \n",
      "                                                                 dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10)           0           lambda_1[3][0]                   \n",
      "                                                                 lambda_1[4][0]                   \n",
      "                                                                 lambda_1[5][0]                   \n",
      "                                                                 lambda_1[6][0]                   \n",
      "                                                                 lambda_1[7][0]                   \n",
      "                                                                 lambda_1[8][0]                   \n",
      "                                                                 lambda_1[9][0]                   \n",
      "                                                                 lambda_1[10][0]                  \n",
      "                                                                 lambda_1[11][0]                  \n",
      "                                                                 lambda_1[12][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#加一個softmax\n",
    "model_output = Activation(\"softmax\")(concatenate_layer)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "# 你的model.summary理論上會長這樣\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.5092 - accuracy: 0.8790 - val_loss: 0.3100 - val_accuracy: 0.9150\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.2938 - accuracy: 0.9186 - val_loss: 0.2624 - val_accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2588 - accuracy: 0.9273 - val_loss: 0.2396 - val_accuracy: 0.9335\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.2364 - accuracy: 0.9336 - val_loss: 0.2271 - val_accuracy: 0.9351\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2189 - accuracy: 0.9386 - val_loss: 0.2114 - val_accuracy: 0.9382\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.2053 - accuracy: 0.9428 - val_loss: 0.1975 - val_accuracy: 0.9422\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1930 - accuracy: 0.9452 - val_loss: 0.1900 - val_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1824 - accuracy: 0.9479 - val_loss: 0.1829 - val_accuracy: 0.9461\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1733 - accuracy: 0.9510 - val_loss: 0.1742 - val_accuracy: 0.9481\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1654 - accuracy: 0.9533 - val_loss: 0.1690 - val_accuracy: 0.9499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b0188faa48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile & fit\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lambda_1_5/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_6/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_7/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_8/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_9/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_10/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_11/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_12/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_13/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_14/Mean:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_3/concat:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda0ce9368b2d704c2e9be59ed432e4e65b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
